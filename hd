#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Class imbalance utilities for Label Studio or COCO annotations.

Features:
- Parse Label Studio JSON (task/annotation style) or COCO.
- Optionally include a 'background' class for images with no boxes.
- Compute class counts, proportions, and basic stats.
- Export class weights (for CE loss) and a weighted sampling list.
- Export a balanced/oversampled image list per class.

Usage examples:
  # Stats only
  python class_imbalance.py --input ls_annotations.json --fmt labelstudio --out_dir out_stats

  # Add background class via --background
  python class_imbalance.py --input combined.json --fmt labelstudio --background --out_dir out_stats

  # Make balanced list (upsample minorities to max count)
  python class_imbalance.py --input coco.json --fmt coco --make_balanced --out_dir out_stats

  # Export PyTorch sampler weights & class weights
  python class_imbalance.py --input ls.json --fmt labelstudio --export_sampler --export_class_weights --out_dir out_stats
"""

import argparse, json, math, os, collections, csv
from pathlib import Path
from typing import Dict, List, Tuple, Any

def _safe_mkdir(p: str):
    Path(p).mkdir(parents=True, exist_ok=True)

# -----------------------------
# Parsing helpers
# -----------------------------
def parse_labelstudio(path: str, label_key: str = "labels") -> Tuple[List[Dict], Dict[int, str]]:
    """
    Parse Label Studio JSON export (tasks). Returns:
      - records: list of dicts with keys: image, labels(list[str])
      - idx2class: mapping for stable class indexing (alphabetical)
    Notes:
      * Supports both result['value']['rectanglelabels'] and result['value']['labels']
      * Assumes data image path is at item['data']['image'] (S3 base64 path or URL/local)
    """
    data = json.loads(Path(path).read_text())
    records = []
    all_labels = set()

    def _extract_labels(result_obj: Dict[str, Any]) -> List[str]:
        v = result_obj.get("value", {})
        # LS rectangle labels key names vary (e.g., 'rectanglelabels' or 'labels')
        return v.get("rectanglelabels") or v.get("labels") or []

    for item in data:
        img = item.get("data", {}).get("image") or item.get("image") or ""
        labels_this_image = []
        # Some exports store annotations under "annotations", others under "predictions"
        containers = []
        if "annotations" in item: containers += item["annotations"]
        if "predictions" in item: containers += item["predictions"]

        for c in containers:
            results = c.get("result", []) or []
            for r in results:
                labels = _extract_labels(r)
                for lab in labels:
                    labels_this_image.append(lab)
                    all_labels.add(lab)

        records.append({"image": img, "labels": labels_this_image})

    classes = sorted(all_labels)
    idx2class = {i: c for i, c in enumerate(classes)}
    return records, idx2class

def parse_coco(path: str) -> Tuple[List[Dict], Dict[int, str]]:
    """
    Parse COCO annotations (instances). Returns records and idx2class.
    record: {image: image_path_or_file_name, labels: [category_name,...]}
    """
    coco = json.loads(Path(path).read_text())
    images = {img["id"]: img for img in coco["images"]}
    cats = {cat["id"]: cat["name"] for cat in coco["categories"]}

    # group annotations by image
    anns_by_img = collections.defaultdict(list)
    for ann in coco.get("annotations", []):
        anns_by_img[ann["image_id"]].append(ann)

    records = []
    all_labels = set()

    for img_id, img in images.items():
        labels = []
        for ann in anns_by_img.get(img_id, []):
            cname = cats.get(ann["category_id"])
            if cname:
                labels.append(cname)
                all_labels.add(cname)
        # Prefer 'coco_url' or full path if present; fallback to 'file_name'
        image_path = img.get("coco_url") or img.get("file_name")
        records.append({"image": image_path, "labels": labels})

    classes = sorted(all_labels)
    idx2class = {i: c for i, c in enumerate(classes)}
    return records, idx2class

# -----------------------------
# Stats & balancing
# -----------------------------
def build_df_like(records: List[Dict], add_background: bool) -> Tuple[Dict[str, int], Dict[str, int], int]:
    """
    Derive per-class counts and image counts (multi-label aware).
    Returns:
      class_counts: occurrences of each class across boxes
      image_counts: images that contain each class at least once
      num_images: total images
    If add_background=True, adds 'background' for images with no labels.
    """
    class_counts = collections.Counter()
    image_counts = collections.Counter()
    num_images = len(records)

    for r in records:
        labs = r["labels"]
        if not labs and add_background:
            labs = ["background"]
        for lab in labs:
            class_counts[lab] += 1
        for lab in set(labs):
            image_counts[lab] += 1
    return dict(class_counts), dict(image_counts), num_images

def compute_class_weights(class_counts: Dict[str, int], power: float = 1.0) -> Dict[str, float]:
    """
    Inverse-frequency style weights for CE loss.
    weight_c = (median_count / count_c)^power (clipped)
    """
    counts = [max(1, c) for c in class_counts.values()]
    med = sorted(counts)[len(counts)//2]
    weights = {}
    for k, c in class_counts.items():
        w = (med / max(1, c)) ** power
        weights[k] = round(float(w), 6)
    return weights

def make_balanced_image_list(records: List[Dict], target: str = "max", add_background: bool = False) -> List[str]:
    """
    Oversample per-class to reach target count ('max' or 'median').
    Produces a flat list of image paths (can contain duplicates).
    Uses MULTI-LABEL heuristic: an image is counted for every class it has.
    """
    # Build per-class image sets
    per_class_images = collections.defaultdict(list)
    for r in records:
        labs = r["labels"]
        if not labs and add_background:
            labs = ["background"]
        for lab in set(labs):
            per_class_images[lab].append(r["image"])

    class_sizes = {k: len(v) for k, v in per_class_images.items()}
    if not class_sizes:
        return []

    if target == "max":
        tgt = max(class_sizes.values())
    elif target == "median":
        vals = sorted(class_sizes.values())
        tgt = vals[len(vals)//2]
    else:
        # numeric
        try:
            tgt = int(target)
        except:
            tgt = max(class_sizes.values())

    balanced = []
    for lab, imgs in per_class_images.items():
        if not imgs:
            continue
        reps = math.ceil(tgt / len(imgs))
        upsampled = (imgs * reps)[:tgt]
        balanced.extend(upsampled)
    return balanced

def export_stats(out_dir: str,
                 class_counts: Dict[str, int],
                 image_counts: Dict[str, int],
                 num_images: int):
    _safe_mkdir(out_dir)
    # CSV summary
    p = Path(out_dir) / "class_stats.csv"
    with p.open("w", newline="") as f:
        w = csv.writer(f)
        w.writerow(["class", "box_count", "image_count", "box_proportion"])
        total_boxes = max(1, sum(class_counts.values()))
        for c in sorted(class_counts.keys()):
            w.writerow([c, class_counts[c], image_counts.get(c, 0), round(class_counts[c]/total_boxes, 6)])

    # JSON summary
    summary = {
        "num_images": num_images,
        "total_boxes": sum(class_counts.values()),
        "class_counts": class_counts,
        "image_counts": image_counts
    }
    (Path(out_dir) / "class_stats.json").write_text(json.dumps(summary, indent=2))

def export_class_weights(out_dir: str, weights: Dict[str, float]):
    _safe_mkdir(out_dir)
    (Path(out_dir) / "class_weights.json").write_text(json.dumps(weights, indent=2))

def export_sampler_weights(out_dir: str, records: List[Dict], class_weights: Dict[str, float], add_background: bool):
    """
    Per-image sampling weight = sum of class weights for its (unique) labels.
    Export list aligned with images.csv for PyTorch WeightedRandomSampler.
    """
    _safe_mkdir(out_dir)
    rows = []
    for r in records:
        labs = r["labels"]
        if not labs and add_background:
            labs = ["background"]
        w = sum(class_weights.get(l, 0.0) for l in set(labs)) or 1.0
        rows.append((r["image"], w))
    with (Path(out_dir) / "sampler_weights.csv").open("w", newline="") as f:
        w = csv.writer(f)
        w.writerow(["image", "weight"])
        w.writerows(rows)

def export_balanced_list(out_dir: str, images: List[str], name: str = "balanced_images.txt"):
    _safe_mkdir(out_dir)
    (Path(out_dir) / name).write_text("\n".join(images))

# -----------------------------
# CLI
# -----------------------------
def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--input", required=True, help="Path to annotations JSON (Label Studio or COCO).")
    ap.add_argument("--fmt", required=True, choices=["labelstudio", "coco"], help="Input format.")
    ap.add_argument("--background", action="store_true", help="Count images with no boxes as 'background' class.")
    ap.add_argument("--make_balanced", action="store_true", help="Export oversampled balanced image list.")
    ap.add_argument("--balanced_target", default="max", help="'max'|'median'|<int> target per-class image count.")
    ap.add_argument("--export_sampler", action="store_true", help="Export sampler_weights.csv for WeightedRandomSampler.")
    ap.add_argument("--export_class_weights", action="store_true", help="Export class_weights.json for CE loss.")
    ap.add_argument("--weights_power", type=float, default=1.0, help="Exponent for class weight scaling (default 1.0).")
    ap.add_argument("--out_dir", required=True, help="Directory to write outputs.")
    args = ap.parse_args()

    if args.fmt == "labelstudio":
        records, idx2class = parse_labelstudio(args.input)
    else:
        records, idx2class = parse_coco(args.input)

    class_counts, image_counts, num_images = build_df_like(records, add_background=args.background)
    export_stats(args.out_dir, class_counts, image_counts, num_images)

    # class weights
    if args.export_class_weights:
        cw = compute_class_weights(class_counts, power=args.weights_power)
        export_class_weights(args.out_dir, cw)

    # sampler weights
    if args.export_sampler:
        cw = compute_class_weights(class_counts, power=args.weights_power)
        export_sampler_weights(args.out_dir, records, cw, add_background=args.background)

    # balanced list
    if args.make_balanced:
        blist = make_balanced_image_list(records, target=args.balanced_target, add_background=args.background)
        export_balanced_list(args.out_dir, blist)

    print(f"[OK] Wrote outputs to: {args.out_dir}")

if __name__ == "__main__":
    main()

